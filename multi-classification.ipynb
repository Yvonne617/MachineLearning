{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "from sklearn.svm import LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)Choos 70% of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "\n",
       "   MFCCs_ 8  MFCCs_ 9  MFCCs_10    ...     MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
       "0 -0.150063 -0.171128  0.124676    ...    -0.108351 -0.077623 -0.009568   \n",
       "1 -0.222475 -0.207693  0.170883    ...    -0.090974 -0.056510 -0.035303   \n",
       "2 -0.242234 -0.219153  0.232538    ...    -0.050691 -0.023590 -0.066722   \n",
       "3 -0.194347 -0.098181  0.270375    ...    -0.136009 -0.177037 -0.130498   \n",
       "4 -0.265423 -0.172700  0.266434    ...    -0.048885 -0.053074 -0.088550   \n",
       "\n",
       "   MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus         Species  \\\n",
       "0  0.057684  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "1  0.020140  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "2 -0.025083  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "3 -0.054766 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "4 -0.031346  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "\n",
       "   RecordID  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, random_state=42, test_size=0.30, shuffle=True)\n",
    "train.index = range(len(train))\n",
    "test.index = range(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)i:\n",
    "### Exact match: The predict labels is exactly the same as the real labels is called exact match. We could use accuracy to calculate the value.\n",
    "### hamming score/loss: In multiclass classification, the Hamming loss corresponds to the Hamming distance between y_true and y_pred which is similar to the Zero one loss function, the calculation formula = （1/n)*(hamming distance/m) (n:#of instances, m: #of labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.iloc[:,0:22]\n",
    "x_test = test.iloc[:,0:22]\n",
    "fa_train = train.iloc[:,22]\n",
    "fa_test = test.iloc[:,22]\n",
    "ge_train = train.iloc[:,23]\n",
    "ge_test = test.iloc[:,23]\n",
    "sp_train = train.iloc[:,24]\n",
    "sp_test = test.iloc[:,24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)ii Train a SVM for each of the labels,using Gaussian kernels and one versus all classifiers.\n",
    "### First we train SVM with large and small parameters o n the whole training data and choose the parameter ranges for gamma = np.logspace(-1,2,10) and c = 10^-1,....10^5 .\n",
    "### Best parameter for gamma=2.154435, C=100.000000.\n",
    "### After using Gaussian kernels the exact match using all labels and all classes is 0.9874942102825383, the average hamming loss is  0.008028408213679172."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score 0.8091709124594719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#We Assume the threhold for the accuracy is 0.6\n",
    "clf = SVC(C=10**-1,kernel='rbf')\n",
    "clf.fit(x_train,fa_train)\n",
    "fa1 = clf.predict(x_test)\n",
    "print(\"The accuracy score\",accuracy_score(fa_test,fa1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score 0.9865678554886521\n"
     ]
    }
   ],
   "source": [
    "clf2 = SVC(C=10**5,kernel='rbf')\n",
    "clf2.fit(x_train,fa_train)\n",
    "fa2 = clf2.predict(x_test)\n",
    "print(\"The accuracy score\",accuracy_score(fa_test,fa2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score 0.9453450671607225\n"
     ]
    }
   ],
   "source": [
    "clf3 = SVC(gamma=0.125,kernel='rbf')\n",
    "clf3.fit(x_train,fa_train)\n",
    "fa3 = clf3.predict(x_test)\n",
    "print(\"The accuracy score\",accuracy_score(fa_test,fa3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score 0.8161185734136174\n"
     ]
    }
   ],
   "source": [
    "clf4 = SVC(gamma=100,kernel='rbf')\n",
    "clf4.fit(x_train,fa_train)\n",
    "fa4 = clf4.predict(x_test)\n",
    "print(\"The accuracy score\",accuracy_score(fa_test,fa4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to the test we make we decide to choose\n",
    "#### gamma = np.logspace(-1,2,10) and \n",
    "#### c = 10^-1,....10^5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\"estimator__C\": [10**-1,10**0,10**1,10**2,10**3,10**4,10**5], \"estimator__gamma\":np.logspace(-1,2,10)}\n",
    "model = OneVsRestClassifier(SVC(kernel='rbf',max_iter=2000))\n",
    "\n",
    "# Fit the grid search\n",
    "gs = GridSearchCV(estimator=model, param_grid=params_dict, cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=2000, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "          n_jobs=None),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'estimator__C': [0.1, 1, 10, 100, 1000, 10000, 100000], 'estimator__gamma': array([  0.1    ,   0.21544,   0.46416,   1.     ,   2.15443,   4.64159,\n",
       "        10.     ,  21.54435,  46.41589, 100.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(x_train, fa_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_pred = gs.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV(estimator=model, param_grid=params_dict, cv=10,scoring='accuracy')\n",
    "gs1.fit(x_train,ge_train)\n",
    "ge_pred = gs1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GridSearchCV(estimator=model, param_grid=params_dict, cv=10,scoring='accuracy')\n",
    "gs2.fit(x_train,sp_train)\n",
    "sp_pred=gs2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score using Gaussian kernels and one versus all classifiers = 0.993646 (gamma=2.154435, C=100.000000)\n"
     ]
    }
   ],
   "source": [
    "gs.best_params_\n",
    "best_gamma = gs.best_params_ ['estimator__gamma']  \n",
    "best_C = gs.best_params_['estimator__C']\n",
    "print('Best score using Gaussian kernels and one versus all classifiers = %f (gamma=%f, C=%f)' % (gs.best_score_, best_gamma, best_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_multi(y_true,y_pred):\n",
    "    ham_distance=[]\n",
    "    for i in range(len(y_pred)):\n",
    "        ham_distance.append(hamming_loss(y_true.values.tolist()[i],y_pred.values.tolist()[i]))\n",
    "    return(np.mean(ham_distance))\n",
    "\n",
    "def exactmatch(y_true,y_pred):\n",
    "    exact_match=0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_pred.iloc[i,0]==y_true.iloc[i,22] and y_pred.iloc[i,1]==y_true.iloc[i,23] and y_pred.iloc[i,2]==y_true.iloc[i,24]:\n",
    "            exact_match+=1\n",
    "    return exact_match/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact match for all the labels: 0.9874942102825383\n",
      "The average hamming loss for all the labels: 0.008028408213679172\n"
     ]
    }
   ],
   "source": [
    "pre_label = pd.DataFrame()\n",
    "pre_label[\"Family\"] = fa_pred\n",
    "pre_label[\"Genus\"] = ge_pred\n",
    "pre_label[\"Species\"] = sp_pred\n",
    "\n",
    "print(\"The exact match for all the labels:\",exactmatch(test,pre_label))\n",
    "print(\"The average hamming loss for all the labels:\",hamming_multi(test.iloc[:,22:25],pre_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (C) iii:Repeat 1(b)ii and L1-penalized SVMs\n",
    "\n",
    "### The exact match for all the labels = 0.9101435849930524,The average hamming loss=0.05697081982399259."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = OneVsRestClassifier(LinearSVC(loss='squared_hinge', penalty='l1', dual=False,max_iter=5000))\n",
    "params_dict1 = {\"estimator__C\": np.logspace(-1, 2, 10),               }\n",
    "# Fit the grid search\n",
    "gs1 = GridSearchCV(estimator=svm, param_grid=params_dict1,cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1.fit(x_train, fa_train)\n",
    "fa_pred1 = gs1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GridSearchCV(estimator=svm, param_grid=params_dict1,cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2.fit(x_train, ge_train)\n",
    "ge_pred1 = gs2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3 = GridSearchCV(estimator=svm, param_grid=params_dict1,cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3.fit(x_train, sp_train)\n",
    "sp_pred1 = gs3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact match for all the labels: 0.9101435849930524\n",
      "The average hamming loss for all the labels: 0.05697081982399259\n"
     ]
    }
   ],
   "source": [
    "pre_label1 = pd.DataFrame()\n",
    "pre_label1[\"Family\"] = fa_pred1\n",
    "pre_label1[\"Genus\"] = ge_pred1\n",
    "pre_label1[\"Species\"] = sp_pred1\n",
    "\n",
    "print(\"The exact match for all the labels:\",exactmatch(test,pre_label1))\n",
    "print(\"The average hamming loss for all the labels:\",hamming_multi(test.iloc[:,22:25],pre_label1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) iv:Using SMOTE to remedy the class imbalance\n",
    "### The exact match for all the labels = 0.9884205650764243，The average hamming loss =  0.008182800679326847.\n",
    "\n",
    "## Conclusion:\n",
    "### According to the classifiers we trained the SVM using gaussian kernel and linear kernel, and after smote using gaussian kernel as well. The conclusion is that when we don't remedy the imbalance data, the linear kenerl better performs worse than the gaussian kernel using the same method to train each label and one vs all classifiers. After we using smote, the result is better than we not smote using gaussian kernel. the best performance classifier is  the Gaussian kernel with the SMOTE method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sme = SMOTE()\n",
    "fa_train = train.iloc[:,22]\n",
    "xfa_res, fa_res = sme.fit_sample(x_train, fa_train)\n",
    "xge_res, ge_res = sme.fit_sample(x_train, ge_train)\n",
    "xsp_res,sp_res = sme.fit_sample(x_train, sp_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict1 = {\"estimator__C\": [10**-1,10**0,10**1,10**2], \"estimator__gamma\":np.logspace(0,2,5)}\n",
    "model1 = OneVsRestClassifier(SVC(kernel='rbf',max_iter=2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote1 = GridSearchCV(estimator=model1, param_grid=params_dict1, cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote1.fit(xfa_res, fa_res)\n",
    "fa_smote_pred = gs_smote1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote2 = GridSearchCV(estimator=model1, param_grid=params_dict1, cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote2.fit(xge_res, ge_res)\n",
    "ge_smote_pred = gs_smote2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote3 = GridSearchCV(estimator=model1, param_grid=params_dict1, cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_smote3.fit(xsp_res,sp_res)\n",
    "sp_smote_pred = gs_smote3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The exact match for all the labels: 0.9884205650764243\n",
      "The average hamming loss for all the labels: 0.008182800679326847\n"
     ]
    }
   ],
   "source": [
    "pre_label2 = pd.DataFrame()\n",
    "pre_label2[\"Family\"] = fa_smote_pred \n",
    "pre_label2[\"Genus\"] = ge_smote_pred\n",
    "pre_label2[\"Species\"] = sp_smote_pred\n",
    "\n",
    "print(\"The exact match for all the labels:\",exactmatch(test,pre_label2))\n",
    "print(\"The average hamming loss for all the labels:\",hamming_multi(test.iloc[:,22:25],pre_label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework2 K-means cluster\n",
    "## After the Monte-Carlo Simulation: \n",
    "### Average hamming distance for all the clusters = 0.8456462531330827, the total hamming distance = 6084.42479129253, the std= 0.0015865521728015127."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a):Use k-means clustering on the whole dataset\n",
    "### According to the silhoutte score we find the best k = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e3d2c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df.iloc[:,:22].values\n",
    "Scores = []  \n",
    "for k in range(2, 11):\n",
    "    estimator = KMeans(n_clusters=k)  \n",
    "    cluster_labels=estimator.fit(data)\n",
    "    Scores.append(silhouette_score(data,estimator.labels_, metric='euclidean'))\n",
    "X = range(2, 11)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silohouettes')\n",
    "plt.plot(X, Scores, 'o-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo Simulation: Perform the following procedures 50 times, and report the average and standard deviation of the 50 Hamming Distances that I calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamming(y_true,y_pred):\n",
    "    ham_distance=[]\n",
    "    for i in range(len(y_pred)):\n",
    "        ham_distance.append(hamming_loss(y_true,y_pred.values.tolist()[i]))\n",
    "    return(np.mean(ham_distance)*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator=KMeans(n_clusters=4)\n",
    "res=estimator.fit_predict(data)\n",
    "lable_pred=estimator.labels_\n",
    "centroids=estimator.cluster_centers_\n",
    "inertia=estimator.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "aver_dis = []\n",
    "for i in range(1,51,1):\n",
    "    c1_label=[]\n",
    "    c2_label=[]\n",
    "    c3_label=[]\n",
    "    c4_label=[]\n",
    "    estimator=KMeans(n_clusters=4)\n",
    "    res=estimator.fit_predict(data)\n",
    "    lable_pred=estimator.labels_\n",
    "    c1 = pd.DataFrame(columns=df.columns)\n",
    "    c2 = pd.DataFrame(columns=df.columns)\n",
    "    c3 = pd.DataFrame(columns=df.columns)\n",
    "    c4 = pd.DataFrame(columns=df.columns) \n",
    "    for i in range(len(data)):\n",
    "        if int(lable_pred[i])==0:\n",
    "            c1 = c1.append(df.iloc[i,:])\n",
    "        if int(lable_pred[i])==1:\n",
    "            c2 = c2.append(df.iloc[i,:])\n",
    "        if int(lable_pred[i])==2:\n",
    "            c3 = c3.append(df.iloc[i,:])\n",
    "        if int(lable_pred[i])==3:\n",
    "            c4 = c4.append(df.iloc[i,:])\n",
    "    fa_result1 = pd.value_counts(c1[\"Family\"].values)\n",
    "    fa_result2 = pd.value_counts(c2[\"Family\"].values)\n",
    "    fa_result3 = pd.value_counts(c3[\"Family\"].values)\n",
    "    fa_result4 = pd.value_counts(c4[\"Family\"].values)\n",
    "    ge_result1 = pd.value_counts(c1[\"Genus\"].values)\n",
    "    ge_result2 = pd.value_counts(c2[\"Genus\"].values)\n",
    "    ge_result3 = pd.value_counts(c3[\"Genus\"].values)\n",
    "    ge_result4 = pd.value_counts(c4[\"Genus\"].values)\n",
    "    sp_result1 = pd.value_counts(c1[\"Species\"].values)\n",
    "    sp_result2 = pd.value_counts(c2[\"Species\"].values)\n",
    "    sp_result3 = pd.value_counts(c3[\"Species\"].values)\n",
    "    sp_result4 = pd.value_counts(c4[\"Species\"].values)\n",
    "    c1_label=[fa_result1.index[0],ge_result1.index[0],sp_result1.index[0]]\n",
    "    c2_label=[fa_result2.index[0],ge_result2.index[0],sp_result2.index[0]]\n",
    "    c3_label=[fa_result3.index[0],ge_result3.index[0],sp_result3.index[0]]\n",
    "    c4_label=[fa_result4.index[0],ge_result4.index[0],sp_result4.index[0]]\n",
    "    c1_pred = c1.iloc[:,22:25]\n",
    "    c2_pred = c2.iloc[:,22:25]\n",
    "    c3_pred = c3.iloc[:,22:25]\n",
    "    c4_pred = c4.iloc[:,22:25]\n",
    "    h1 = Hamming(c1_label,c1_pred)\n",
    "    h2 = Hamming(c2_label,c2_pred)\n",
    "    h3 = Hamming(c3_label,c3_pred)\n",
    "    h4 = Hamming(c4_label,c4_pred)\n",
    "    aver_dis.append((h1+h2+h3+h4)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of the distance after 50 times procedures: 0.8456462531330827\n",
      "The std of the distance after 50 times procedures: 0.0015865521728015127\n"
     ]
    }
   ],
   "source": [
    "print(\"The average of the distance after 50 times procedures:\",np.mean(aver_dis))\n",
    "print(\"The std of the distance after 50 times procedures:\",np.std(aver_dis))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
